package github.com/hashicorp/terraform-provider-azurerm/internal/services/datafactory
import (
	"fmt"
	"time"

	"github.com/hashicorp/go-azure-sdk/resource-manager/datafactory/2018-06-01/factories"
	"github.com/hashicorp/terraform-provider-azurerm/helpers/tf"
	"github.com/hashicorp/terraform-provider-azurerm/internal/clients"
	"github.com/hashicorp/terraform-provider-azurerm/internal/services/datafactory/parse"
	"github.com/hashicorp/terraform-provider-azurerm/internal/services/datafactory/validate"
	"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk"
	"github.com/hashicorp/terraform-provider-azurerm/internal/tf/validation"
	"github.com/hashicorp/terraform-provider-azurerm/internal/timeouts"
	"github.com/hashicorp/terraform-provider-azurerm/utils"
	"github.com/jackofallops/kermit/sdk/datafactory/2018-06-01/datafactory" // nolint: staticcheck
)
func resourceDataFactoryLinkedServiceAzureFileStorageCreateUpdate(d *pluginsdk.ResourceData, meta interface{}) error {
	client := meta.(*clients.Client).DataFactory.LinkedServiceClient
	subscriptionId := meta.(*clients.Client).DataFactory.LinkedServiceClient.SubscriptionID
	ctx, cancel := timeouts.ForCreateUpdate(meta.(*clients.Client).StopContext, d)
	defer cancel()

	dataFactoryId, err := factories.ParseFactoryID(d.Get("data_factory_id").(string))
	if err != nil {
		return err
	}

	id := parse.NewLinkedServiceID(subscriptionId, dataFactoryId.ResourceGroupName, dataFactoryId.FactoryName, d.Get("name").(string))

	if d.IsNewResource() {
		existing, err := client.Get(ctx, id.ResourceGroup, id.FactoryName, id.Name, "")
		if err != nil {
			if !utils.ResponseWasNotFound(existing.Response) {
				return fmt.Errorf("checking for presence of existing Data Factory Azure File Storage Anonymous %s: %+v", id, err)
			}
		}

		if !utils.ResponseWasNotFound(existing.Response) {
			return tf.ImportAsExistsError("azurerm_data_factory_linked_service_azure_file_storage", id.ID())
		}
	}

	fileStorageProperties := &datafactory.AzureFileStorageLinkedServiceTypeProperties{
		ConnectionString: &datafactory.SecureString{
			Value: utils.String(d.Get("connection_string").(string)),
			Type:  datafactory.TypeSecureString,
		},
		FileShare: d.Get("file_share").(string),
	}

	if host := d.Get("host").(string); host != "" {
		fileStorageProperties.Host = host
	}

	if userId := d.Get("user_id").(string); userId != "" {
		fileStorageProperties.UserID = userId
	}

	password := d.Get("password").(string)
	if password != "" {
		fileStorageProperties.Password = &datafactory.SecureString{
			Value: utils.String(d.Get("password").(string)),
			Type:  datafactory.TypeSecureString,
		}
	}

	fileStorageLinkedService := &datafactory.AzureFileStorageLinkedService{
		Description: utils.String(d.Get("description").(string)),
		AzureFileStorageLinkedServiceTypeProperties: fileStorageProperties,
		Type: datafactory.TypeBasicLinkedServiceTypeAzureFileStorage,
	}

	if v, ok := d.GetOk("parameters"); ok {
		fileStorageLinkedService.Parameters = expandLinkedServiceParameters(v.(map[string]interface{}))
	}

	if v, ok := d.GetOk("integration_runtime_name"); ok {
		fileStorageLinkedService.ConnectVia = expandDataFactoryLinkedServiceIntegrationRuntime(v.(string))
	}

	if v, ok := d.GetOk("key_vault_password"); ok {
		password := v.([]interface{})
		fileStorageProperties.Password = expandAzureKeyVaultSecretReference(password)
	}

	if v, ok := d.GetOk("additional_properties"); ok {
		fileStorageLinkedService.AdditionalProperties = v.(map[string]interface{})
	}

	if v, ok := d.GetOk("annotations"); ok {
		annotations := v.([]interface{})
		fileStorageLinkedService.Annotations = &annotations
	}

	linkedService := datafactory.LinkedServiceResource{
		Properties: fileStorageLinkedService,
	}

	if _, err := client.CreateOrUpdate(ctx, id.ResourceGroup, id.FactoryName, id.Name, linkedService, ""); err != nil {
		return fmt.Errorf("creating/updating Data Factory Azure File Storage %s: %+v", id, err)
	}

	d.SetId(id.ID())

	return resourceDataFactoryLinkedServiceAzureFileStorageRead(d, meta)
}
