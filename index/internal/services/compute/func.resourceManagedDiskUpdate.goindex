package github.com/hashicorp/terraform-provider-azurerm/internal/services/compute
import (
	"context"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/hashicorp/go-azure-helpers/lang/pointer"
	"github.com/hashicorp/go-azure-helpers/lang/response"
	"github.com/hashicorp/go-azure-helpers/resourcemanager/commonids"
	"github.com/hashicorp/go-azure-helpers/resourcemanager/commonschema"
	"github.com/hashicorp/go-azure-helpers/resourcemanager/location"
	"github.com/hashicorp/go-azure-helpers/resourcemanager/tags"
	"github.com/hashicorp/go-azure-sdk/resource-manager/compute/2022-03-02/diskaccesses"
	"github.com/hashicorp/go-azure-sdk/resource-manager/compute/2023-04-02/disks"
	"github.com/hashicorp/go-azure-sdk/resource-manager/compute/2024-03-01/virtualmachines"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-provider-azurerm/helpers/azure"
	"github.com/hashicorp/terraform-provider-azurerm/helpers/tf"
	"github.com/hashicorp/terraform-provider-azurerm/internal/clients"
	"github.com/hashicorp/terraform-provider-azurerm/internal/locks"
	"github.com/hashicorp/terraform-provider-azurerm/internal/services/compute/migration"
	"github.com/hashicorp/terraform-provider-azurerm/internal/services/compute/validate"
	"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk"
	"github.com/hashicorp/terraform-provider-azurerm/internal/tf/suppress"
	"github.com/hashicorp/terraform-provider-azurerm/internal/tf/validation"
	"github.com/hashicorp/terraform-provider-azurerm/internal/timeouts"
	"github.com/hashicorp/terraform-provider-azurerm/utils"
)
func resourceManagedDiskUpdate(d *pluginsdk.ResourceData, meta interface{}) error {
	client := meta.(*clients.Client).Compute.DisksClient
	virtualMachinesClient := meta.(*clients.Client).Compute.VirtualMachinesClient
	skusClient := meta.(*clients.Client).Compute.SkusClient
	ctx, cancel := timeouts.ForUpdate(meta.(*clients.Client).StopContext, d)
	defer cancel()

	log.Printf("[INFO] preparing arguments for Azure ARM Managed Disk update.")

	name := d.Get("name").(string)
	resourceGroup := d.Get("resource_group_name").(string)
	maxShares := d.Get("max_shares").(int)
	storageAccountType := d.Get("storage_account_type").(string)
	diskSizeGB := d.Get("disk_size_gb").(int)
	onDemandBurstingEnabled := d.Get("on_demand_bursting_enabled").(bool)
	shouldShutDown := false
	shouldDetach := false
	expandedDisk := virtualmachines.DataDisk{}

	id, err := commonids.ParseManagedDiskID(d.Id())
	if err != nil {
		return err
	}

	disk, err := client.Get(ctx, *id)
	if err != nil {
		if response.WasNotFound(disk.HttpResponse) {
			return fmt.Errorf("managed disk %q (Resource Group %q) was not found", name, resourceGroup)
		}

		return fmt.Errorf("making Read request on Azure Managed Disk %q (Resource Group %q): %+v", name, resourceGroup, err)
	}

	diskUpdate := disks.DiskUpdate{
		Properties: &disks.DiskUpdateProperties{},
	}

	if d.HasChange("max_shares") {
		diskUpdate.Properties.MaxShares = utils.Int64(int64(maxShares))
		var skuName disks.DiskStorageAccountTypes
		for _, v := range disks.PossibleValuesForDiskStorageAccountTypes() {
			if strings.EqualFold(storageAccountType, v) {
				skuName = disks.DiskStorageAccountTypes(v)
			}
		}
		diskUpdate.Sku = &disks.DiskSku{
			Name: &skuName,
		}
	}

	if d.HasChange("tier") {
		if storageAccountType != string(disks.DiskStorageAccountTypesPremiumZRS) && storageAccountType != string(disks.DiskStorageAccountTypesPremiumLRS) {
			return fmt.Errorf("`tier` can only be specified when `storage_account_type` is set to `Premium_LRS` or `Premium_ZRS`")
		}
		shouldShutDown = true
		tier := d.Get("tier").(string)
		diskUpdate.Properties.Tier = &tier
	}

	if d.HasChange("tags") {
		t := d.Get("tags").(map[string]interface{})
		diskUpdate.Tags = tags.Expand(t)
	}

	if d.HasChange("storage_account_type") {
		shouldShutDown = true
		var skuName disks.DiskStorageAccountTypes
		for _, v := range disks.PossibleValuesForDiskStorageAccountTypes() {
			if strings.EqualFold(storageAccountType, v) {
				skuName = disks.DiskStorageAccountTypes(v)
			}
		}
		diskUpdate.Sku = &disks.DiskSku{
			Name: &skuName,
		}
	}

	if strings.EqualFold(storageAccountType, string(disks.DiskStorageAccountTypesUltraSSDLRS)) || storageAccountType == string(disks.DiskStorageAccountTypesPremiumVTwoLRS) {
		if d.HasChange("disk_iops_read_write") {
			v := d.Get("disk_iops_read_write")
			diskIOPS := int64(v.(int))
			diskUpdate.Properties.DiskIOPSReadWrite = &diskIOPS
		}

		if d.HasChange("disk_mbps_read_write") {
			v := d.Get("disk_mbps_read_write")
			diskMBps := int64(v.(int))
			diskUpdate.Properties.DiskMBpsReadWrite = &diskMBps
		}

		if d.HasChange("disk_iops_read_only") {
			if maxShares == 0 {
				return fmt.Errorf("[ERROR] disk_iops_read_only is only available for UltraSSD disks with shared disk enabled")
			}

			v := d.Get("disk_iops_read_only")
			diskUpdate.Properties.DiskIOPSReadOnly = utils.Int64(int64(v.(int)))
		}

		if d.HasChange("disk_mbps_read_only") {
			if maxShares == 0 {
				return fmt.Errorf("[ERROR] disk_mbps_read_only is only available for UltraSSD disks with shared disk enabled")
			}

			v := d.Get("disk_mbps_read_only")
			diskUpdate.Properties.DiskMBpsReadOnly = utils.Int64(int64(v.(int)))
		}
	} else if d.HasChange("disk_iops_read_write") || d.HasChange("disk_mbps_read_write") || d.HasChange("disk_iops_read_only") || d.HasChange("disk_mbps_read_only") {
		return fmt.Errorf("[ERROR] disk_iops_read_write, disk_mbps_read_write, disk_iops_read_only and disk_mbps_read_only are only available for UltraSSD disks and PremiumV2 disks")
	}

	if d.HasChange("optimized_frequent_attach_enabled") {
		diskUpdate.Properties.OptimizedForFrequentAttach = pointer.To(d.Get("optimized_frequent_attach_enabled").(bool))
	}

	if d.HasChange("os_type") {
		operatingSystemType := disks.OperatingSystemTypes(d.Get("os_type").(string))
		diskUpdate.Properties.OsType = &operatingSystemType
	}

	if d.HasChange("disk_size_gb") {
		if oldSize, newSize := d.GetChange("disk_size_gb"); newSize.(int) > oldSize.(int) {
			canBeResizedWithoutDowntime := false
			if meta.(*clients.Client).Features.ManagedDisk.ExpandWithoutDowntime {
				diskSupportsNoDowntimeResize := determineIfDataDiskSupportsNoDowntimeResize(disk.Model, oldSize.(int), newSize.(int))

				vmSkuSupportsNoDowntimeResize, err := determineIfVirtualMachineSkuSupportsNoDowntimeResize(ctx, disk.Model.ManagedBy, virtualMachinesClient, skusClient)
				if err != nil {
					return fmt.Errorf("determining if the Virtual Machine the Disk is attached to supports no-downtime-resize: %+v", err)
				}

				// If a disk is 4 TiB or less, you can't expand it beyond 4 TiB without detaching it from the VM.
				shouldDetach = oldSize.(int) < 4096 && newSize.(int) >= 4096

				canBeResizedWithoutDowntime = *vmSkuSupportsNoDowntimeResize && *diskSupportsNoDowntimeResize
			}
			if !canBeResizedWithoutDowntime {
				log.Printf("[INFO] The %s, or the Virtual Machine that it's attached to, doesn't support no-downtime-resizing - requiring that the VM should be shutdown", *id)
				shouldShutDown = true
			}
			diskUpdate.Properties.DiskSizeGB = utils.Int64(int64(newSize.(int)))
		} else {
			return fmt.Errorf("- New size must be greater than original size. Shrinking disks is not supported on Azure")
		}
	}

	if d.HasChange("encryption_settings") {
		diskUpdate.Properties.EncryptionSettingsCollection = expandManagedDiskEncryptionSettings(d.Get("encryption_settings").([]interface{}))
	}

	if d.HasChange("disk_encryption_set_id") {
		shouldShutDown = true
		if diskEncryptionSetId := d.Get("disk_encryption_set_id").(string); diskEncryptionSetId != "" {
			encryptionType, err := retrieveDiskEncryptionSetEncryptionType(ctx, meta.(*clients.Client).Compute.DiskEncryptionSetsClient, diskEncryptionSetId)
			if err != nil {
				return err
			}

			diskUpdate.Properties.Encryption = &disks.Encryption{
				Type:                encryptionType,
				DiskEncryptionSetId: utils.String(diskEncryptionSetId),
			}
		} else {
			return fmt.Errorf("once a customer-managed key is used, you canâ€™t change the selection back to a platform-managed key")
		}
	}

	if networkAccessPolicy := d.Get("network_access_policy").(string); networkAccessPolicy != "" {
		policy := disks.NetworkAccessPolicy(networkAccessPolicy)
		diskUpdate.Properties.NetworkAccessPolicy = &policy
	} else {
		allowAllPolicy := disks.NetworkAccessPolicyAllowAll
		diskUpdate.Properties.NetworkAccessPolicy = &allowAllPolicy
	}

	if diskAccessID := d.Get("disk_access_id").(string); d.HasChange("disk_access_id") {
		switch {
		case *diskUpdate.Properties.NetworkAccessPolicy == disks.NetworkAccessPolicyAllowPrivate:
			diskUpdate.Properties.DiskAccessId = utils.String(diskAccessID)
		case diskAccessID != "" && *diskUpdate.Properties.NetworkAccessPolicy != disks.NetworkAccessPolicyAllowPrivate:
			return fmt.Errorf("[ERROR] disk_access_id is only available when network_access_policy is set to AllowPrivate")
		default:
			diskUpdate.Properties.DiskAccessId = nil
		}
	}

	if d.HasChange("public_network_access_enabled") {
		if d.Get("public_network_access_enabled").(bool) {
			networkAccessEnabled := disks.PublicNetworkAccessEnabled
			diskUpdate.Properties.PublicNetworkAccess = &networkAccessEnabled
		} else {
			networkAccessDisabled := disks.PublicNetworkAccessDisabled
			diskUpdate.Properties.PublicNetworkAccess = &networkAccessDisabled
		}
	}

	if onDemandBurstingEnabled {
		switch storageAccountType {
		case string(disks.DiskStorageAccountTypesPremiumLRS):
		case string(disks.DiskStorageAccountTypesPremiumZRS):
		default:
			return fmt.Errorf("`on_demand_bursting_enabled` can only be set to true when `storage_account_type` is set to `Premium_LRS` or `Premium_ZRS`")
		}

		if diskSizeGB != 0 && diskSizeGB <= 512 {
			return fmt.Errorf("`on_demand_bursting_enabled` can only be set to true when `disk_size_gb` is larger than 512GB")
		}
	}

	if d.HasChange("on_demand_bursting_enabled") {
		shouldShutDown = true
		diskUpdate.Properties.BurstingEnabled = utils.Bool(onDemandBurstingEnabled)
	}

	// whilst we need to shut this down, if we're not attached to anything there's no point
	if shouldShutDown && disk.Model.ManagedBy == nil {
		shouldShutDown = false
	}

	// if we are attached to a VM we bring down the VM as necessary for the operations which are not allowed while it's online
	if shouldShutDown {
		virtualMachineId, err := virtualmachines.ParseVirtualMachineID(*disk.Model.ManagedBy)
		if err != nil {
			return fmt.Errorf("parsing VMID %q for disk attachment: %+v", *disk.Model.ManagedBy, err)
		}
		// check instanceView State

		locks.ByName(name, VirtualMachineResourceName)
		defer locks.UnlockByName(name, VirtualMachineResourceName)

		vm, err := virtualMachinesClient.Get(ctx, *virtualMachineId, virtualmachines.DefaultGetOperationOptions())
		if err != nil {
			return fmt.Errorf("retrieving %s: %+v", virtualMachineId, err)
		}

		instanceView, err := virtualMachinesClient.InstanceView(ctx, *virtualMachineId)
		if err != nil {
			return fmt.Errorf("retrieving InstanceView for %s: %+v", virtualMachineId, err)
		}

		shouldTurnBackOn := virtualMachineShouldBeStarted(instanceView.Model)
		shouldDeallocate := true

		if instanceView.Model != nil && instanceView.Model.Statuses != nil {
			for _, status := range *instanceView.Model.Statuses {
				if status.Code == nil {
					continue
				}

				// could also be the provisioning state which we're not bothered with here
				state := strings.ToLower(*status.Code)
				if !strings.HasPrefix(state, "powerstate/") {
					continue
				}

				state = strings.TrimPrefix(state, "powerstate/")
				switch strings.ToLower(state) {
				case "deallocated":
					// VM already deallocated, no shutdown and deallocation needed anymore
					shouldShutDown = false
					shouldDeallocate = false
				case "deallocating":
					// VM is deallocating
					// To make sure we do not start updating before this action has finished,
					// only skip the shutdown and send another deallocation request if shouldDeallocate == true
					shouldShutDown = false
				case "stopped":
					shouldShutDown = false
				}
			}
		}

		// Detach
		if shouldDetach {
			dataDisks := make([]virtualmachines.DataDisk, 0)
			if vmModel := vm.Model; vmModel != nil && vmModel.Properties != nil && vmModel.Properties.StorageProfile != nil && vmModel.Properties.StorageProfile.DataDisks != nil {
				for _, dataDisk := range *vmModel.Properties.StorageProfile.DataDisks {
					// since this field isn't (and shouldn't be) case-sensitive; we're deliberately not using `strings.EqualFold`
					if dataDisk.Name != nil && *dataDisk.Name != id.DiskName {
						dataDisks = append(dataDisks, dataDisk)
					} else {
						if dataDisk.Caching != nil && *dataDisk.Caching != virtualmachines.CachingTypesNone {
							return fmt.Errorf("`disk_size_gb` can't be increased above 4095GB when `caching` is set to anything other than `None`")
						}
						expandedDisk = dataDisk
					}
				}

				vmModel.Properties.StorageProfile.DataDisks = &dataDisks

				// fixes #2485
				vmModel.Identity = nil
				// fixes #1600
				vmModel.Resources = nil

				if err := virtualMachinesClient.CreateOrUpdateThenPoll(ctx, *virtualMachineId, *vm.Model, virtualmachines.DefaultCreateOrUpdateOperationOptions()); err != nil {
					return fmt.Errorf("removing Disk %q from %s : %+v", id.DiskName, virtualMachineId, err)
				}
			}
		}

		// Shutdown
		if shouldShutDown {
			log.Printf("[DEBUG] Shutting Down %s", virtualMachineId)
			options := virtualmachines.DefaultPowerOffOperationOptions()
			options.SkipShutdown = pointer.To(false)
			if err := virtualMachinesClient.PowerOffThenPoll(ctx, *virtualMachineId, options); err != nil {
				return fmt.Errorf("sending Power Off to %s: %+v", virtualMachineId, err)
			}

			log.Printf("[DEBUG] Shut Down %s", virtualMachineId)
		}

		// De-allocate
		if shouldDeallocate {
			log.Printf("[DEBUG] Deallocating %s.", virtualMachineId)
			// Upgrading to 2021-07-01 exposed a new hibernate paramater to the Deallocate method
			if err := virtualMachinesClient.DeallocateThenPoll(ctx, *virtualMachineId, virtualmachines.DefaultDeallocateOperationOptions()); err != nil {
				return fmt.Errorf("deallocating to %s: %+v", virtualMachineId, err)
			}
			log.Printf("[DEBUG] Deallocated %s", virtualMachineId)
		}

		// Update Disk
		err = client.UpdateThenPoll(ctx, *id, diskUpdate)
		if err != nil {
			return fmt.Errorf("updating Managed Disk %q (Resource Group %q): %+v", name, resourceGroup, err)
		}

		// Reattach DataDisk
		if shouldDetach && vm.Model.Properties.StorageProfile != nil {
			disks := *vm.Model.Properties.StorageProfile.DataDisks

			expandedDisk.DiskSizeGB = diskUpdate.Properties.DiskSizeGB
			disks = append(disks, expandedDisk)

			vm.Model.Properties.StorageProfile.DataDisks = &disks

			// fixes #2485
			vm.Model.Identity = nil
			// fixes #1600
			vm.Model.Resources = nil

			// if there's too many disks we get a 409 back with:
			//   `The maximum number of data disks allowed to be attached to a VM of this size is 1.`
			// which we're intentionally not wrapping, since the errors good.
			if err := virtualMachinesClient.CreateOrUpdateThenPoll(ctx, *virtualMachineId, *vm.Model, virtualmachines.DefaultCreateOrUpdateOperationOptions()); err != nil {
				return fmt.Errorf("updating %s to reattach Disk %q: %+v", virtualMachineId, name, err)
			}
		}

		if shouldTurnBackOn && (shouldShutDown || shouldDeallocate) {
			log.Printf("[DEBUG] Starting %s", virtualMachineId)
			if err := virtualMachinesClient.StartThenPoll(ctx, *virtualMachineId); err != nil {
				return fmt.Errorf("starting %s: %+v", virtualMachineId, err)
			}
			log.Printf("[DEBUG] Started %s", virtualMachineId)
		}
	} else { // otherwise, just update it
		err := client.UpdateThenPoll(ctx, *id, diskUpdate)
		if err != nil {
			return fmt.Errorf("expanding managed disk %q (Resource Group %q): %+v", name, resourceGroup, err)
		}
	}

	return resourceManagedDiskRead(d, meta)
}
